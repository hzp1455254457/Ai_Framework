"""
ç®€å•èŠå¤©ç¤ºä¾‹è„šæœ¬
åŠŸèƒ½æè¿°ï¼šæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨AIæ¡†æ¶è¿›è¡Œç®€å•çš„é—®ç­”å¯¹è¯
ä½¿ç”¨æ–¹æ³•ï¼špython simple_chat_example.py
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from infrastructure.config import ConfigManager
from core.llm.service import LLMService


async def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºç®€å•çš„é—®ç­”å¯¹è¯"""
    
    print("=" * 60)
    print("AIæ¡†æ¶ç®€å•èŠå¤©ç¤ºä¾‹")
    print("=" * 60)
    print()
    
    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“‹ æ­£åœ¨åŠ è½½é…ç½®...")
        config_manager = ConfigManager.load(env="dev")
        config = config_manager.config
        
        # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®
        qwen_api_key = config.get("llm", {}).get("adapters", {}).get("qwen-adapter", {}).get("api_key", "")
        deepseek_api_key = config.get("llm", {}).get("adapters", {}).get("deepseek-adapter", {}).get("api_key", "")
        
        if not qwen_api_key and not deepseek_api_key:
            print("âŒ é”™è¯¯ï¼šæœªé…ç½®APIå¯†é’¥")
            print("è¯·åœ¨ config/default.yaml æˆ– config/dev.yaml ä¸­é…ç½®APIå¯†é’¥")
            return
        
        # 2. åˆ›å»ºLLMæœåŠ¡
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–LLMæœåŠ¡...")
        service = LLMService(config)
        await service.initialize()
        print(f"âœ… LLMæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"   é»˜è®¤æ¨¡å‹: {config.get('llm', {}).get('default_model', 'unknown')}")
        print(f"   å·²æ³¨å†Œé€‚é…å™¨: {list(service._adapters.keys())}")
        print()
        
        # 3. å‡†å¤‡é—®é¢˜
        question = "ä½ å¥½ ä½ å–œæ¬¢ä»€ä¹ˆä¸œè¥¿"
        messages = [{"role": "user", "content": question}]
        
        print("=" * 60)
        print(f"ğŸ’¬ é—®é¢˜: {question}")
        print("=" * 60)
        print()
        
        # 4. å¦‚æœé…ç½®äº†åƒé—®ï¼Œä½¿ç”¨åƒé—®å›ç­”
        if qwen_api_key:
            print("ğŸ¤– ä½¿ç”¨é€šä¹‰åƒé—®å›ç­”:")
            print("-" * 60)
            try:
                response = await service.chat(messages, model="qwen-turbo")
                print(response.content)
                print()
                print(f"ğŸ“Š Tokenä½¿ç”¨æƒ…å†µ:")
                print(f"   - æç¤ºToken: {response.usage.get('prompt_tokens', 0)}")
                print(f"   - å®ŒæˆToken: {response.usage.get('completion_tokens', 0)}")
                print(f"   - æ€»Token: {response.total_tokens}")
                print()
            except Exception as e:
                print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
                print()
        
        # 5. å¦‚æœé…ç½®äº†DeepSeekï¼Œä½¿ç”¨DeepSeekå›ç­”
        if deepseek_api_key:
            print("ğŸ¤– ä½¿ç”¨DeepSeekå›ç­”:")
            print("-" * 60)
            try:
                response = await service.chat(messages, model="deepseek-chat")
                print(response.content)
                print()
                print(f"ğŸ“Š Tokenä½¿ç”¨æƒ…å†µ:")
                print(f"   - æç¤ºToken: {response.usage.get('prompt_tokens', 0)}")
                print(f"   - å®ŒæˆToken: {response.usage.get('completion_tokens', 0)}")
                print(f"   - æ€»Token: {response.total_tokens}")
                print()
            except Exception as e:
                print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
                print()
        
        # 6. æ¸…ç†èµ„æº
        await service.cleanup()
        print("=" * 60)
        print("âœ… ç¤ºä¾‹æ‰§è¡Œå®Œæˆ")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
